{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os\n",
    "import pickle\n",
    "import logging\n",
    "import multiprocessing\n",
    "from pathlib import Path\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "\n",
    "import arviz as az\n",
    "import numpyro\n",
    "\n",
    "from hbmep.config import Config\n",
    "from hbmep.model.utils import Site as site\n",
    "\n",
    "PLATFORM = \"cpu\"\n",
    "jax.config.update(\"jax_platforms\", PLATFORM)\n",
    "numpyro.set_platform(PLATFORM)\n",
    "\n",
    "cpu_count = multiprocessing.cpu_count() - 2\n",
    "numpyro.set_host_device_count(cpu_count)\n",
    "numpyro.enable_x64()\n",
    "numpyro.enable_validation()\n",
    "\n",
    "logger = logging.getLogger(__name__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpyro.distributions as dist\n",
    "from hbmep.model import Baseline\n",
    "\n",
    "\n",
    "class RectifiedLogistic(Baseline):\n",
    "    LINK = \"rectified_logistic\"\n",
    "\n",
    "    def __init__(self, config: Config):\n",
    "        super(RectifiedLogistic, self).__init__(config=config)\n",
    "        self.combination_columns = self.features + [self.subject]\n",
    "\n",
    "    def _model(self, subject, features, intensity, response_obs=None):\n",
    "        subject, n_subject = subject\n",
    "        features, n_features = features\n",
    "        intensity, n_data = intensity\n",
    "\n",
    "        intensity = intensity.reshape(-1, 1)\n",
    "        intensity = np.tile(intensity, (1, self.n_response))\n",
    "\n",
    "        feature0 = features[0].reshape(-1,)\n",
    "        n_feature0 = n_features[0]\n",
    "\n",
    "        with numpyro.plate(site.n_response, self.n_response, dim=-1):\n",
    "            global_sigma_b = numpyro.sample(\"global_sigma_b\", dist.HalfNormal(100))\n",
    "            global_sigma_v = numpyro.sample(\"global_sigma_v\", dist.HalfNormal(100))\n",
    "\n",
    "            global_sigma_L = numpyro.sample(\"global_sigma_L\", dist.HalfNormal(1))\n",
    "            global_sigma_l = numpyro.sample(\"global_sigma_l\", dist.HalfNormal(100))\n",
    "            global_sigma_H = numpyro.sample(\"global_sigma_H\", dist.HalfNormal(5))\n",
    "\n",
    "            global_sigma_g_1 = numpyro.sample(\"global_sigma_g_1\", dist.HalfNormal(100))\n",
    "            global_sigma_g_2 = numpyro.sample(\"global_sigma_g_2\", dist.HalfNormal(100))\n",
    "\n",
    "            global_sigma_p = numpyro.sample(\"global_sigma_p\", dist.HalfNormal(100))\n",
    "\n",
    "            with numpyro.plate(\"n_feature0\", n_feature0, dim=-2):\n",
    "                \"\"\" Hyper-priors \"\"\"\n",
    "                mu_a = numpyro.sample(site.mu_a, dist.HalfNormal(scale=50))\n",
    "                sigma_a = numpyro.sample(site.sigma_a, dist.HalfNormal(scale=1 / 50))\n",
    "\n",
    "                sigma_b_raw = numpyro.sample(\"sigma_b_raw\", dist.HalfNormal(scale=1))\n",
    "                sigma_b = numpyro.deterministic(site.sigma_b, global_sigma_b * sigma_b_raw)\n",
    "\n",
    "                sigma_v_raw = numpyro.sample(\"sigma_v_raw\", dist.HalfNormal(scale=1))\n",
    "                sigma_v = numpyro.deterministic(site.sigma_v, global_sigma_v * sigma_v_raw)\n",
    "\n",
    "                sigma_L_raw = numpyro.sample(\"sigma_L_raw\", dist.HalfNormal(scale=1))\n",
    "                sigma_L = numpyro.deterministic(site.sigma_L, global_sigma_L * sigma_L_raw)\n",
    "\n",
    "                sigma_l_raw = numpyro.sample(\"sigma_l_raw\", dist.HalfNormal(scale=1))\n",
    "                sigma_l = numpyro.deterministic(\"sigma_l\", global_sigma_l * sigma_l_raw)\n",
    "\n",
    "                sigma_H_raw = numpyro.sample(\"sigma_H_raw\", dist.HalfNormal(scale=1))\n",
    "                sigma_H = numpyro.deterministic(site.sigma_H, global_sigma_H * sigma_H_raw)\n",
    "\n",
    "                sigma_g_1_raw = numpyro.sample(\"sigma_g_1_raw\", dist.HalfNormal(scale=1))\n",
    "                sigma_g_1 = numpyro.deterministic(\"sigma_g_1\", global_sigma_g_1 * sigma_g_1_raw)\n",
    "\n",
    "                sigma_g_2_raw = numpyro.sample(\"sigma_g_2_raw\", dist.HalfNormal(scale=1))\n",
    "                sigma_g_2 = numpyro.deterministic(\"sigma_g_2\", global_sigma_g_2 * sigma_g_2_raw)\n",
    "\n",
    "                sigma_p_raw = numpyro.sample(\"sigma_p_raw\", dist.HalfNormal(scale=1))\n",
    "                sigma_p = numpyro.deterministic(\"sigma_p\", global_sigma_p * sigma_p_raw)\n",
    "\n",
    "                with numpyro.plate(site.n_subject, n_subject, dim=-3):\n",
    "                    \"\"\" Priors \"\"\"\n",
    "                    a_raw = numpyro.sample(\"a_raw\", dist.Gamma(concentration=mu_a * sigma_a, rate=1))\n",
    "                    a = numpyro.deterministic(site.a, (1 / sigma_a) * a_raw)\n",
    "\n",
    "                    b_raw = numpyro.sample(\"b_raw\", dist.HalfNormal(scale=1))\n",
    "                    b = numpyro.deterministic(site.b, sigma_b * b_raw)\n",
    "\n",
    "                    v_raw = numpyro.sample(\"v_raw\", dist.HalfNormal(scale=1))\n",
    "                    v = numpyro.deterministic(site.v, sigma_v * v_raw)\n",
    "\n",
    "                    L_raw = numpyro.sample(\"L_raw\", dist.HalfNormal(scale=1))\n",
    "                    L = numpyro.deterministic(site.L, sigma_L * L_raw)\n",
    "\n",
    "                    l_raw = numpyro.sample(\"l_raw\", dist.HalfNormal(scale=1))\n",
    "                    l = numpyro.deterministic(\"l\", sigma_l * l_raw)\n",
    "\n",
    "                    H_raw = numpyro.sample(\"H_raw\", dist.HalfNormal(scale=1))\n",
    "                    H = numpyro.deterministic(site.H, sigma_H * H_raw)\n",
    "\n",
    "                    g_1_raw = numpyro.sample(\"g_1_raw\", dist.HalfCauchy(scale=1))\n",
    "                    g_1 = numpyro.deterministic(site.g_1, sigma_g_1 * g_1_raw)\n",
    "\n",
    "                    g_2_raw = numpyro.sample(\"g_2_raw\", dist.HalfCauchy(scale=1))\n",
    "                    g_2 = numpyro.deterministic(site.g_2, sigma_g_2 * g_2_raw)\n",
    "\n",
    "                    p_raw = numpyro.sample(\"p_raw\", dist.HalfNormal(scale=1))\n",
    "                    p = numpyro.deterministic(\"p\", sigma_p * p_raw)\n",
    "\n",
    "        with numpyro.plate(site.n_response, self.n_response, dim=-1):\n",
    "            with numpyro.plate(site.data, n_data, dim=-2):\n",
    "                \"\"\" Model \"\"\"\n",
    "                mu = numpyro.deterministic(\n",
    "                    site.mu,\n",
    "                    L[subject, feature0]\n",
    "                    + jnp.where(\n",
    "                        intensity <= a[subject, feature0],\n",
    "                        0,\n",
    "                        -l[subject, feature0]\n",
    "                        + (\n",
    "                            (H[subject, feature0] + l[subject, feature0])\n",
    "                            / jnp.power(\n",
    "                                1\n",
    "                                + (\n",
    "                                    (\n",
    "                                        -1\n",
    "                                        + jnp.power(\n",
    "                                            (H[subject, feature0] + l[subject, feature0]) / l[subject, feature0],\n",
    "                                            v[subject, feature0]\n",
    "                                        )\n",
    "                                    )\n",
    "                                    * jnp.exp(-b[subject, feature0] * (intensity - a[subject, feature0]))\n",
    "                                ),\n",
    "                                1 / v[subject, feature0]\n",
    "                            )\n",
    "                        )\n",
    "                    )\n",
    "                )\n",
    "                beta = numpyro.deterministic(\n",
    "                    site.beta,\n",
    "                    g_1[subject, feature0] + g_2[subject, feature0] * jnp.power(1 / (mu + 1), p[subject, feature0])\n",
    "                )\n",
    "\n",
    "                \"\"\" Observation \"\"\"\n",
    "                numpyro.sample(\n",
    "                    site.obs,\n",
    "                    dist.Gamma(concentration=mu * beta, rate=beta),\n",
    "                    obs=response_obs\n",
    "                )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-10-30 11:40:37,874 - hbmep.config - INFO - Verifying configuration ...\n",
      "2023-10-30 11:40:37,875 - hbmep.config - INFO - Success!\n",
      "2023-10-30 11:40:37,888 - hbmep.model.baseline - INFO - Initialized model with rectified_logistic link\n"
     ]
    }
   ],
   "source": [
    "toml_path = \"/home/vishu/repos/hbmep-paper/configs/paper/tms/bits/A03_rec96_quants.toml\"\n",
    "\n",
    "config = Config(toml_path=toml_path)\n",
    "config.BUILD_DIR = \"/home/vishu/repos/hbmep-paper/reports/paper/tms/bits/A03_rec96_quants\"\n",
    "config.BUILD_DIR = os.path.join(config.BUILD_DIR, \"downsampled\")\n",
    "\n",
    "# config.MCMC_PARAMS[\"num_warmup\"] = 10000\n",
    "# config.MCMC_PARAMS[\"num_samples\"] = 12000\n",
    "# config.MCMC_PARAMS[\"thinning\"] = 4\n",
    "\n",
    "model = RectifiedLogistic(config=config)\n",
    "\n",
    "# from numpyro.infer import NUTS\n",
    "# sampler = NUTS(model=model._model, max_tree_depth=50)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "src = \"/home/vishu/data/hbmep-processed/human/tms/bits/A03 rec96 quants.xlsx\"\n",
    "df = pd.read_excel(src)\n",
    "\n",
    "# subset = [\"SCA01\"]\n",
    "# ind = df[model.subject].isin(subset)\n",
    "# df = df[ind].reset_index(drop=True).copy()\n",
    "\n",
    "# df, encoder_dict = model.load(df=df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_map = {\n",
    "    \"Filename\": model.subject,\n",
    "    \"Delivered (Eonly)\": model.intensity,\n",
    "    \"PeaktoPeak\": model.response[0]\n",
    "}\n",
    "\n",
    "df = df.rename(columns=columns_map).copy()\n",
    "df[model.features[0]] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "subset = [\"SCA03_VRT0_RAPB_TMS_REC_10242023-12-27-15_eventonly\"]\n",
    "ind = df[model.subject].isin(subset)\n",
    "df = df[ind].reset_index(drop=True).copy()\n",
    "\n",
    "ind = df[model.intensity] > 0\n",
    "df = df[ind].reset_index(drop=True).copy()\n",
    "\n",
    "df = df.astype({model.subject: 'object', model.intensity: np.float64, model.response[0]: np.float64}).copy()\n",
    "df = df.sort_values(by=[model.intensity]).reset_index(drop=True).copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(48, 11)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.iloc[0::2, :].reset_index(drop=True).copy()\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-10-30 11:40:38,456 - hbmep.dataset.core - INFO - Artefacts will be stored here - /home/vishu/repos/hbmep-paper/reports/paper/tms/bits/A03_rec96_quants/downsampled\n",
      "2023-10-30 11:40:38,456 - hbmep.dataset.core - INFO - Copied config to /home/vishu/repos/hbmep-paper/reports/paper/tms/bits/A03_rec96_quants/downsampled\n",
      "2023-10-30 11:40:38,457 - hbmep.dataset.core - INFO - Processing data ...\n",
      "2023-10-30 11:40:38,458 - hbmep.utils.utils - INFO - func:load took: 0.00 sec\n"
     ]
    }
   ],
   "source": [
    "df, encoder_dict = model.load(df=df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-10-30 11:40:38,542 - hbmep.model.baseline - INFO - Running inference with rectified_logistic ...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4007415c05f54d408c312eba7571a3da",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0e96e2e8ca9340308f86025fd3441783",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3d257bd7304b4c0fbaadd1bde79e7838",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dab376eb51014da28cff1ca2aa6a7ab6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-10-30 11:42:13,082 - hbmep.utils.utils - INFO - func:run_inference took: 1 min and 34.54 sec\n"
     ]
    }
   ],
   "source": [
    "mcmc, posterior_samples = model.run_inference(df=df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-10-30 11:42:13,179 - hbmep.utils.utils - INFO - func:make_prediction_dataset took: 0.00 sec\n",
      "2023-10-30 11:42:14,341 - hbmep.utils.utils - INFO - func:predict took: 1.16 sec\n",
      "2023-10-30 11:42:14,343 - hbmep.model.baseline - INFO - Rendering ...\n",
      "2023-10-30 11:42:14,692 - hbmep.model.baseline - INFO - Saved to /home/vishu/repos/hbmep-paper/reports/paper/tms/bits/A03_rec96_quants/downsampled/recruitment_curves.pdf\n",
      "2023-10-30 11:42:14,692 - hbmep.utils.utils - INFO - func:render_recruitment_curves took: 0.35 sec\n",
      "2023-10-30 11:42:14,695 - hbmep.model.baseline - INFO - Rendering Posterior Predictive Check ...\n",
      "2023-10-30 11:42:15,095 - hbmep.model.baseline - INFO - Saved to /home/vishu/repos/hbmep-paper/reports/paper/tms/bits/A03_rec96_quants/downsampled/posterior_predictive_check.pdf\n",
      "2023-10-30 11:42:15,095 - hbmep.utils.utils - INFO - func:_render_predictive_check took: 0.40 sec\n",
      "2023-10-30 11:42:15,095 - hbmep.utils.utils - INFO - func:render_predictive_check took: 0.40 sec\n"
     ]
    }
   ],
   "source": [
    "prediction_df = model.make_prediction_dataset(df=df)\n",
    "posterior_predictive = model.predict(df=prediction_df, posterior_samples=posterior_samples)\n",
    "\n",
    "model.render_recruitment_curves(df=df, encoder_dict=encoder_dict, posterior_samples=posterior_samples, prediction_df=prediction_df, posterior_predictive=posterior_predictive)\n",
    "model.render_predictive_check(df=df, encoder_dict=encoder_dict, prediction_df=prediction_df, posterior_predictive=posterior_predictive)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "                         mean       std    median      2.5%     97.5%     n_eff     r_hat\n",
      "       H_raw[0,0,0]      0.80      0.53      0.68      0.06      1.85   2060.31      1.00\n",
      "       L_raw[0,0,0]      0.47      0.48      0.30      0.00      1.45   2527.68      1.00\n",
      "       a_raw[0,0,0]      3.63      1.94      3.39      0.32      7.27   1331.54      1.00\n",
      "       b_raw[0,0,0]      0.39      0.46      0.21      0.00      1.38   2898.61      1.00\n",
      "     g_1_raw[0,0,0]      1.31      3.00      0.68      0.03      4.20   2114.73      1.00\n",
      "     g_2_raw[0,0,0]     44.69    147.34     12.27      0.53    174.91   1582.04      1.00\n",
      "  global_sigma_H[0]      3.93      2.61      3.35      0.32      9.17   2237.07      1.00\n",
      "  global_sigma_L[0]      0.44      0.47      0.27      0.00      1.43   2904.36      1.00\n",
      "  global_sigma_b[0]     38.63     45.62     21.01      0.03    134.61   2820.51      1.00\n",
      "global_sigma_g_1[0]     67.66     51.20     54.76      0.89    168.08   2459.51      1.00\n",
      "global_sigma_g_2[0]    122.63     64.90    114.94      9.23    243.55   2967.33      1.00\n",
      "  global_sigma_l[0]     62.92     54.20     47.89      0.24    169.80   3364.18      1.00\n",
      "  global_sigma_p[0]     90.82     55.89     80.38      7.10    198.04   2141.90      1.00\n",
      "  global_sigma_v[0]    103.63     63.57     93.67      1.69    224.52   3900.42      1.00\n",
      "       l_raw[0,0,0]      0.64      0.54      0.49      0.00      1.73   3418.57      1.00\n",
      "       p_raw[0,0,0]      0.90      0.56      0.79      0.05      1.96   2191.29      1.00\n",
      "   sigma_H_raw[0,0]      0.78      0.52      0.66      0.06      1.80   2109.81      1.00\n",
      "   sigma_L_raw[0,0]      0.45      0.46      0.28      0.00      1.40   2733.65      1.00\n",
      "   sigma_b_raw[0,0]      0.41      0.46      0.24      0.00      1.38   2799.86      1.00\n",
      " sigma_g_1_raw[0,0]      0.66      0.52      0.53      0.01      1.69   2538.24      1.00\n",
      " sigma_g_2_raw[0,0]      1.24      0.64      1.17      0.09      2.46   2376.78      1.00\n",
      "   sigma_l_raw[0,0]      0.65      0.55      0.50      0.00      1.75   3342.96      1.00\n",
      "   sigma_p_raw[0,0]      0.89      0.56      0.78      0.07      1.98   2082.92      1.00\n",
      "   sigma_v_raw[0,0]      1.02      0.64      0.92      0.00      2.23   3316.29      1.00\n",
      "       v_raw[0,0,0]      1.03      0.65      0.93      0.00      2.24   3092.62      1.00\n",
      "           µ_a[0,0]      3.93      2.17      3.62      0.40      8.09   1752.27      1.00\n",
      "           σ_a[0,0]      0.10      0.06      0.10      0.01      0.21   1322.87      1.00\n",
      "\n",
      "Number of divergences: 383\n"
     ]
    }
   ],
   "source": [
    "mcmc.print_summary(prob=.95)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-10-30 10:39:53,619 - __main__ - INFO - Evaluating model ...\n",
      "/home/vishu/repos/hbmep-paper/.venv/lib/python3.11/site-packages/arviz/stats/stats.py:803: UserWarning: Estimated shape parameter of Pareto distribution is greater than 0.7 for one or more samples. You should consider using a more robust model, this is because importance sampling is less likely to work well if the marginal posterior and LOO posterior are very different. This is more likely to happen with a non-robust model and highly influential observations.\n",
      "  warnings.warn(\n",
      "2023-10-30 10:39:53,752 - __main__ - INFO - ELPD LOO (Log): 45.75\n"
     ]
    }
   ],
   "source": [
    "numpyro_data = az.from_numpyro(mcmc)\n",
    "\n",
    "\"\"\" Model evaluation \"\"\"\n",
    "logger.info(\"Evaluating model ...\")\n",
    "\n",
    "score = az.loo(numpyro_data)\n",
    "logger.info(f\"ELPD LOO (Log): {score.elpd_loo:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-10-27 15:51:53,418 - __main__ - INFO - Evaluating model ...\n",
      "/home/vishu/repos/hbmep-paper/.venv/lib/python3.11/site-packages/arviz/stats/stats.py:1037: RuntimeWarning: overflow encountered in exp\n",
      "  weights = 1 / np.exp(len_scale - len_scale[:, None]).sum(axis=1)\n",
      "/home/vishu/repos/hbmep-paper/.venv/lib/python3.11/site-packages/arviz/stats/stats.py:803: UserWarning: Estimated shape parameter of Pareto distribution is greater than 0.7 for one or more samples. You should consider using a more robust model, this is because importance sampling is less likely to work well if the marginal posterior and LOO posterior are very different. This is more likely to happen with a non-robust model and highly influential observations.\n",
      "  warnings.warn(\n",
      "2023-10-27 15:51:59,497 - __main__ - INFO - ELPD LOO (Log): 9011.30\n",
      "/home/vishu/repos/hbmep-paper/.venv/lib/python3.11/site-packages/arviz/stats/stats.py:1645: UserWarning: For one or more samples the posterior variance of the log predictive densities exceeds 0.4. This could be indication of WAIC starting to fail. \n",
      "See http://arxiv.org/abs/1507.04544 for details\n",
      "  warnings.warn(\n",
      "2023-10-27 15:51:59,700 - __main__ - INFO - ELPD WAIC (Log): 9033.36\n"
     ]
    }
   ],
   "source": [
    "numpyro_data = az.from_numpyro(mcmc)\n",
    "\n",
    "\"\"\" Model evaluation \"\"\"\n",
    "logger.info(\"Evaluating model ...\")\n",
    "\n",
    "score = az.loo(numpyro_data)\n",
    "logger.info(f\"ELPD LOO (Log): {score.elpd_loo:.2f}\")\n",
    "\n",
    "score = az.waic(numpyro_data)\n",
    "logger.info(f\"ELPD WAIC (Log): {score.elpd_waic:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "dest = os.path.join(model.build_dir, \"inference.pkl\")\n",
    "with open(dest, \"wb\") as f:\n",
    "    pickle.dump((model, mcmc, posterior_samples), f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/vishu/repos/hbmep-paper/reports/paper/tms/link-comparison/rectified_logistic/numpyro_data.nc'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dest = os.path.join(model.build_dir, \"numpyro_data.nc\")\n",
    "az.to_netcdf(numpyro_data, dest)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
