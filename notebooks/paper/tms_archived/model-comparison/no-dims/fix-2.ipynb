{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os\n",
    "import pickle\n",
    "import logging\n",
    "import multiprocessing\n",
    "from pathlib import Path\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "\n",
    "import arviz as az\n",
    "import numpyro\n",
    "\n",
    "from hbmep.config import Config\n",
    "from hbmep.model.utils import Site as site\n",
    "\n",
    "PLATFORM = \"cpu\"\n",
    "jax.config.update(\"jax_platforms\", PLATFORM)\n",
    "numpyro.set_platform(PLATFORM)\n",
    "\n",
    "cpu_count = multiprocessing.cpu_count() - 2\n",
    "numpyro.set_host_device_count(cpu_count)\n",
    "numpyro.enable_x64()\n",
    "numpyro.enable_validation()\n",
    "\n",
    "logger = logging.getLogger(__name__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpyro.distributions as dist\n",
    "from hbmep.model import BaseModel\n",
    "\n",
    "\n",
    "class MixtureModel(BaseModel):\n",
    "    LINK = \"mixture_model\"\n",
    "\n",
    "    def __init__(self, config: Config):\n",
    "        super(MixtureModel, self).__init__(config=config)\n",
    "        self.combination_columns = self.features + [self.subject]\n",
    "\n",
    "    def fn(self, x, a, b, v, L, l, H):\n",
    "        return (\n",
    "            L\n",
    "            + jnp.where(\n",
    "                jnp.less(x, a),\n",
    "                0.,\n",
    "                -l + jnp.true_divide(\n",
    "                    H + l,\n",
    "                    jnp.power(\n",
    "                        1\n",
    "                        + jnp.multiply(\n",
    "                            -1\n",
    "                            + jnp.power(\n",
    "                                jnp.true_divide(H + l, l),\n",
    "                                v\n",
    "                            ),\n",
    "                            jnp.exp(jnp.multiply(-b, x - a))\n",
    "                        ),\n",
    "                        jnp.true_divide(1, v)\n",
    "                    )\n",
    "                )\n",
    "            )\n",
    "        )\n",
    "\n",
    "    def _model(self, subject, features, intensity, response_obs=None):\n",
    "        subject, n_subject = subject\n",
    "        features, n_features = features\n",
    "        intensity, n_data = intensity\n",
    "\n",
    "        intensity = intensity.reshape(-1, 1)\n",
    "        intensity = np.tile(intensity, (1, self.n_response))\n",
    "\n",
    "        feature0 = features[0].reshape(-1,)\n",
    "        n_feature0 = n_features[0]\n",
    "\n",
    "        with numpyro.plate(site.n_response, self.n_response, dim=-1):\n",
    "            \"\"\" Global Priors \"\"\"\n",
    "            # a_mean_global_scale = numpyro.sample(\"a_mean_global_scale\", dist.HalfNormal(100))\n",
    "            # a_shape_global_scale = numpyro.sample(\"a_shape_global_scale\", dist.HalfNormal(100))\n",
    "\n",
    "            b_scale_global_scale = numpyro.sample(\"b_scale_global_scale\", dist.HalfNormal(1))\n",
    "            v_scale_global_scale = numpyro.sample(\"v_scale_global_scale\", dist.HalfNormal(1))\n",
    "\n",
    "            L_scale_global_scale = numpyro.sample(\"L_scale_global_scale\", dist.HalfNormal(10))\n",
    "            l_scale_global_scale = numpyro.sample(\"l_scale_global_scale\", dist.HalfNormal(10))\n",
    "            H_scale_global_scale = numpyro.sample(\"H_scale_global_scale\", dist.HalfNormal(10))\n",
    "\n",
    "            g_1_scale_global_scale = numpyro.sample(\"g_1_scale_global_scale\", dist.HalfNormal(1))\n",
    "            g_2_scale_global_scale = numpyro.sample(\"g_2_scale_global_scale\", dist.HalfNormal(1))\n",
    "\n",
    "            with numpyro.plate(\"n_feature0\", n_feature0, dim=-2):\n",
    "                \"\"\" Hyper-priors \"\"\"\n",
    "                a_mean = numpyro.sample(\"a_mean\", dist.HalfNormal(scale=100))\n",
    "\n",
    "                # a_mean_raw = numpyro.sample(\"a_mean_raw\", dist.HalfNormal(scale=1))\n",
    "                # a_mean = numpyro.deterministic(\"a_mean\", jnp.multiply(a_mean_global_scale, a_mean_raw))\n",
    "\n",
    "                # a_shape_raw = numpyro.sample(\"a_shape_raw\", dist.HalfNormal(scale=1))\n",
    "                # a_shape = numpyro.deterministic(\"a_shape\", jnp.multiply(a_shape_global_scale, a_shape_raw))\n",
    "\n",
    "                b_scale_raw = numpyro.sample(\"b_scale_raw\", dist.HalfNormal(scale=1))\n",
    "                b_scale = numpyro.deterministic(\"b_scale\", jnp.multiply(b_scale_global_scale, b_scale_raw))\n",
    "\n",
    "                v_scale_raw = numpyro.sample(\"v_scale_raw\", dist.HalfNormal(scale=1))\n",
    "                v_scale = numpyro.deterministic(\"v_scale\", jnp.multiply(v_scale_global_scale, v_scale_raw))\n",
    "\n",
    "                L_scale_raw = numpyro.sample(\"L_scale_raw\", dist.HalfNormal(scale=1))\n",
    "                L_scale = numpyro.deterministic(\"L_scale\", jnp.multiply(L_scale_global_scale, L_scale_raw))\n",
    "\n",
    "                l_scale_raw = numpyro.sample(\"l_scale_raw\", dist.HalfNormal(scale=1))\n",
    "                l_scale = numpyro.deterministic(\"sigma_l\", jnp.multiply(l_scale_global_scale, l_scale_raw))\n",
    "\n",
    "                H_scale_raw = numpyro.sample(\"H_scale_raw\", dist.HalfNormal(scale=1))\n",
    "                H_scale = numpyro.deterministic(\"H_scale\", jnp.multiply(H_scale_global_scale, H_scale_raw))\n",
    "\n",
    "                g_1_scale_raw = numpyro.sample(\"g_1_scale_raw\", dist.HalfNormal(scale=1))\n",
    "                g_1_scale = numpyro.deterministic(\"g_1_scale\", jnp.multiply(g_1_scale_global_scale, g_1_scale_raw))\n",
    "\n",
    "                g_2_scale_raw = numpyro.sample(\"g_2_scale_raw\", dist.HalfNormal(scale=1))\n",
    "                g_2_scale = numpyro.deterministic(\"g_2_scale\", jnp.multiply(g_2_scale_global_scale, g_2_scale_raw))\n",
    "\n",
    "                with numpyro.plate(site.n_subject, n_subject, dim=-3):\n",
    "                    \"\"\" Priors \"\"\"\n",
    "                    a_shape = numpyro.sample(\"a_shape\", dist.HalfNormal(scale=10))\n",
    "                    a_raw = numpyro.sample(\"a_raw\", dist.Gamma(concentration=a_shape, rate=1))\n",
    "                    a = numpyro.deterministic(site.a, jnp.true_divide(jnp.multiply(a_raw, a_mean), a_shape))\n",
    "\n",
    "                    b_raw = numpyro.sample(\"b_raw\", dist.HalfNormal(scale=1))\n",
    "                    b = numpyro.deterministic(site.b, jnp.multiply(b_scale, b_raw))\n",
    "\n",
    "                    v_raw = numpyro.sample(\"v_raw\", dist.HalfNormal(scale=1))\n",
    "                    v = numpyro.deterministic(site.v, jnp.multiply(v_scale, v_raw))\n",
    "\n",
    "                    L_raw = numpyro.sample(\"L_raw\", dist.HalfNormal(scale=1))\n",
    "                    L = numpyro.deterministic(site.L, jnp.multiply(L_scale, L_raw))\n",
    "\n",
    "                    l_raw = numpyro.sample(\"l_raw\", dist.HalfNormal(scale=1))\n",
    "                    l = numpyro.deterministic(\"l\", jnp.multiply(l_scale, l_raw))\n",
    "\n",
    "                    H_raw = numpyro.sample(\"H_raw\", dist.HalfNormal(scale=1))\n",
    "                    H = numpyro.deterministic(site.H, jnp.multiply(H_scale, H_raw))\n",
    "\n",
    "                    g_1_raw = numpyro.sample(\"g_1_raw\", dist.HalfCauchy(scale=1))\n",
    "                    g_1 = numpyro.deterministic(site.g_1, jnp.multiply(g_1_scale, g_1_raw))\n",
    "\n",
    "                    g_2_raw = numpyro.sample(\"g_2_raw\", dist.HalfCauchy(scale=1))\n",
    "                    g_2 = numpyro.deterministic(site.g_2, jnp.multiply(g_2_scale, g_2_raw))\n",
    "\n",
    "        # H_penalty_for_small_values = jnp.true_divide(1000, H + 1)\n",
    "        # numpyro.factor(\"H_penalty_for_small_values\", -H_penalty_for_small_values)\n",
    "\n",
    "        \"\"\" Outlier Distribution \"\"\"\n",
    "        outlier_dist_shape = numpyro.sample(\"outlier_dist_shape\", dist.HalfNormal(5))\n",
    "        outlier_dist_rate = numpyro.sample(\"outlier_dist_rate\", dist.HalfNormal(1))\n",
    "\n",
    "        \"\"\" Mixture \"\"\"\n",
    "        if response_obs is not None:\n",
    "            outlier_prob = numpyro.sample(\"outlier_prob\", dist.Uniform(0., .5))\n",
    "        else: # Turn off mixture when predicting\n",
    "            outlier_prob = numpyro.deterministic(\"outlier_prob\", 0.)\n",
    "\n",
    "        mixing_distribution = dist.Categorical(probs=jnp.array([1 - outlier_prob, outlier_prob]))\n",
    "\n",
    "        with numpyro.plate(site.n_response, self.n_response, dim=-1):\n",
    "            with numpyro.plate(site.n_data, n_data, dim=-2):\n",
    "                \"\"\" Model \"\"\"\n",
    "                mu = numpyro.deterministic(\n",
    "                    site.mu,\n",
    "                    self.fn(\n",
    "                        x=intensity,\n",
    "                        a=a[subject, feature0],\n",
    "                        b=b[subject, feature0],\n",
    "                        v=v[subject, feature0],\n",
    "                        L=L[subject, feature0],\n",
    "                        l=l[subject, feature0],\n",
    "                        H=H[subject, feature0]\n",
    "                    )\n",
    "                )\n",
    "                beta = numpyro.deterministic(\n",
    "                    site.beta,\n",
    "                    g_1[subject, feature0] + jnp.true_divide(g_2[subject, feature0], mu)\n",
    "                )\n",
    "\n",
    "                \"\"\" Mixture \"\"\"\n",
    "                component_distributions = [\n",
    "                    dist.Gamma(concentration=jnp.multiply(mu, beta), rate=beta),\n",
    "                    dist.Gamma(concentration=outlier_dist_shape, rate=outlier_dist_rate)\n",
    "                ]\n",
    "                Mixture = dist.MixtureGeneral(\n",
    "                    mixing_distribution=mixing_distribution,\n",
    "                    component_distributions=component_distributions\n",
    "                )\n",
    "\n",
    "                \"\"\" Observation \"\"\"\n",
    "                numpyro.sample(\n",
    "                    site.obs,\n",
    "                    Mixture,\n",
    "                    obs=response_obs\n",
    "                )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-14 11:27:34,386 - hbmep.config - INFO - Verifying configuration ...\n",
      "2023-11-14 11:27:34,386 - hbmep.config - INFO - Success!\n",
      "2023-11-14 11:27:34,400 - hbmep.model.baseline - INFO - Initialized base_model\n"
     ]
    }
   ],
   "source": [
    "toml_path = \"/home/vishu/repos/hbmep-paper/configs/paper/tms/proc-2023-11-13/config.toml\"\n",
    "\n",
    "config = Config(toml_path=toml_path)\n",
    "config.BUILD_DIR = os.path.join(config.BUILD_DIR, \"model-comparison/mixture-model/fix-2\")\n",
    "config.RESPONSE = [\"PKPK_ADM\"]\n",
    "\n",
    "config.MCMC_PARAMS[\"num_warmup\"] = 5000\n",
    "config.MCMC_PARAMS[\"num_samples\"] = 1000\n",
    "\n",
    "model = MixtureModel(config=config)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-14 11:27:34,471 - hbmep.dataset.core - INFO - Artefacts will be stored here - /home/vishu/repos/hbmep-paper/reports/paper/tms/proc-2023-11-13/model-comparison/mixture-model/fix-2\n",
      "2023-11-14 11:27:34,472 - hbmep.dataset.core - INFO - Copied config to /home/vishu/repos/hbmep-paper/reports/paper/tms/proc-2023-11-13/model-comparison/mixture-model/fix-2\n",
      "2023-11-14 11:27:34,472 - hbmep.dataset.core - INFO - Processing data ...\n",
      "2023-11-14 11:27:34,473 - hbmep.utils.utils - INFO - func:load took: 0.00 sec\n"
     ]
    }
   ],
   "source": [
    "src = \"/home/vishu/data/hbmep-processed/human/tms/data_pkpk_auc_proc-2023-11-14.csv\"\n",
    "df = pd.read_csv(src)\n",
    "\n",
    "subset = [\"SCA01\", \"SCA02\", \"SCS04\", \"SCS05\"]\n",
    "ind = df[model.subject].isin(subset)\n",
    "df = df[ind].reset_index(drop=True).copy()\n",
    "\n",
    "# ind = df[model.response[0]] > 0.05\n",
    "# df = df[~ind].reset_index(drop=True).copy()\n",
    "\n",
    "ind = df[model.intensity] > 0\n",
    "df = df[ind].reset_index(drop=True).copy()\n",
    "\n",
    "df, encoder_dict = model.load(df=df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-14 11:27:34,558 - hbmep.model.baseline - INFO - Running inference with base_model ...\n"
     ]
    }
   ],
   "source": [
    "mcmc, posterior_samples = model.run_inference(df=df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-14 11:25:34,363 - hbmep.utils.utils - INFO - func:make_prediction_dataset took: 0.00 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-14 11:25:36,347 - hbmep.utils.utils - INFO - func:predict took: 1.98 sec\n",
      "2023-11-14 11:25:36,347 - hbmep.model.baseline - INFO - Rendering recruitment curves ...\n",
      "2023-11-14 11:25:37,082 - hbmep.model.baseline - INFO - Saved to /home/vishu/repos/hbmep-paper/reports/paper/tms/proc-2023-11-13/model-comparison/mixture-model/fix-2/recruitment_curves.pdf\n",
      "2023-11-14 11:25:37,083 - hbmep.utils.utils - INFO - func:render_recruitment_curves took: 0.74 sec\n",
      "2023-11-14 11:25:37,083 - hbmep.model.baseline - INFO - Rendering posterior predictive checks ...\n",
      "2023-11-14 11:25:37,870 - hbmep.model.baseline - INFO - Saved to /home/vishu/repos/hbmep-paper/reports/paper/tms/proc-2023-11-13/model-comparison/mixture-model/fix-2/posterior_predictive_check.pdf\n",
      "2023-11-14 11:25:37,870 - hbmep.utils.utils - INFO - func:predictive_checks_renderer took: 0.79 sec\n",
      "2023-11-14 11:25:37,870 - hbmep.utils.utils - INFO - func:render_predictive_check took: 0.79 sec\n"
     ]
    }
   ],
   "source": [
    "prediction_df = model.make_prediction_dataset(df=df)\n",
    "posterior_predictive = model.predict(df=prediction_df, posterior_samples=posterior_samples)\n",
    "\n",
    "model.render_recruitment_curves(df=df, encoder_dict=encoder_dict, posterior_samples=posterior_samples, prediction_df=prediction_df, posterior_predictive=posterior_predictive)\n",
    "model.render_predictive_check(df=df, encoder_dict=encoder_dict, prediction_df=prediction_df, posterior_predictive=posterior_predictive)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4000, 2, 1)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a_mean = posterior_samples[\"a_mean\"]\n",
    "a_mean = np.array(a_mean)\n",
    "a_mean.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[325.5505924 ],\n",
       "       [100.55289559]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a_mean.mean(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[320.81682913],\n",
       "        [ 39.97951934]],\n",
       "\n",
       "       [[337.57855357],\n",
       "        [102.80564592]],\n",
       "\n",
       "       [[325.59858444],\n",
       "        [101.84529421]]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "posterior_samples[site.a].mean(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "                               mean       std    median      2.5%     97.5%     n_eff     r_hat\n",
      "             H_raw[0,0,0]      0.78      0.60      0.65      0.00      1.94   2706.31      1.00\n",
      "             H_raw[1,0,0]      0.78      0.59      0.66      0.00      1.92   2087.09      1.00\n",
      "  H_scale_global_scale[0]      3.90      2.95      3.27      0.01      9.74   1862.13      1.00\n",
      "         H_scale_raw[0,0]      0.77      0.61      0.64      0.00      1.96   2108.72      1.00\n",
      "             L_raw[0,0,0]      0.90      0.57      0.79      0.02      1.97   1222.52      1.01\n",
      "             L_raw[1,0,0]      0.34      0.29      0.27      0.00      0.92    901.01      1.01\n",
      "  L_scale_global_scale[0]      0.36      0.42      0.19      0.01      1.26   1176.03      1.00\n",
      "         L_scale_raw[0,0]      0.35      0.41      0.19      0.00      1.20   1003.69      1.00\n",
      "              a_mean[0,0]     36.53     36.19     26.92      0.02    105.37    753.26      1.01\n",
      "             a_raw[0,0,0]    800.25    606.94    673.04      0.30   2026.42    802.78      1.01\n",
      "             a_raw[1,0,0]    781.84    601.99    662.45      1.07   1997.70    843.15      1.01\n",
      "           a_shape[0,0,0]    800.08    605.68    675.10      1.45   2019.34    795.24      1.01\n",
      "           a_shape[1,0,0]    782.59    601.54    663.16      1.20   1997.70    843.08      1.01\n",
      "             b_raw[0,0,0]      0.66      0.54      0.53      0.00      1.74   1624.79      1.00\n",
      "             b_raw[1,0,0]      0.93      0.61      0.85      0.03      2.08   1594.84      1.00\n",
      "  b_scale_global_scale[0]      0.08      0.06      0.07      0.00      0.19   1902.51      1.00\n",
      "         b_scale_raw[0,0]      0.80      0.57      0.69      0.00      1.87   1777.56      1.00\n",
      "           g_1_raw[0,0,0]     17.56     96.66      1.08      0.00     53.51    343.97      1.01\n",
      "           g_1_raw[1,0,0]      1.98      7.03      0.91      0.00      6.31   1858.38      1.00\n",
      "g_1_scale_global_scale[0]     78.39     59.01     67.02      0.02    193.83   2239.60      1.00\n",
      "       g_1_scale_raw[0,0]      0.81      0.59      0.69      0.00      1.90   1873.57      1.00\n",
      "           g_2_raw[0,0,0]     22.39     43.41     10.52      0.00     77.38    728.45      1.00\n",
      "           g_2_raw[1,0,0]      0.22      0.34      0.11      0.00      0.80    818.76      1.00\n",
      "g_2_scale_global_scale[0]     86.77     59.30     74.67      2.73    199.84   1179.11      1.01\n",
      "       g_2_scale_raw[0,0]      0.85      0.59      0.72      0.01      1.98   1270.17      1.00\n",
      "             l_raw[0,0,0]      0.70      0.56      0.56      0.00      1.80   1815.61      1.00\n",
      "             l_raw[1,0,0]      0.91      0.61      0.81      0.00      2.08   1814.06      1.00\n",
      "  l_scale_global_scale[0]      0.17      0.12      0.14      0.00      0.39   1640.45      1.00\n",
      "         l_scale_raw[0,0]      0.84      0.59      0.73      0.01      1.98   1934.86      1.00\n",
      "        outlier_dist_rate      1.49      0.69      1.44      0.33      2.90   1428.33      1.00\n",
      "       outlier_dist_shape      0.53      0.24      0.49      0.14      0.98   1605.05      1.00\n",
      "             outlier_prob      0.05      0.02      0.04      0.01      0.09   1820.91      1.00\n",
      "             v_raw[0,0,0]      0.93      0.62      0.82      0.01      2.09   1473.19      1.00\n",
      "             v_raw[1,0,0]      0.69      0.53      0.56      0.00      1.73   2069.30      1.00\n",
      "  v_scale_global_scale[0]     78.92     56.79     67.81      0.95    189.51   1743.20      1.00\n",
      "         v_scale_raw[0,0]      0.77      0.56      0.67      0.01      1.81   1999.95      1.00\n",
      "\n",
      "Number of divergences: 543\n"
     ]
    }
   ],
   "source": [
    "mcmc.print_summary(prob=.95)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-10-27 15:51:53,418 - __main__ - INFO - Evaluating model ...\n",
      "/home/vishu/repos/hbmep-paper/.venv/lib/python3.11/site-packages/arviz/stats/stats.py:1037: RuntimeWarning: overflow encountered in exp\n",
      "  weights = 1 / np.exp(len_scale - len_scale[:, None]).sum(axis=1)\n",
      "/home/vishu/repos/hbmep-paper/.venv/lib/python3.11/site-packages/arviz/stats/stats.py:803: UserWarning: Estimated shape parameter of Pareto distribution is greater than 0.7 for one or more samples. You should consider using a more robust model, this is because importance sampling is less likely to work well if the marginal posterior and LOO posterior are very different. This is more likely to happen with a non-robust model and highly influential observations.\n",
      "  warnings.warn(\n",
      "2023-10-27 15:51:59,497 - __main__ - INFO - ELPD LOO (Log): 9011.30\n",
      "/home/vishu/repos/hbmep-paper/.venv/lib/python3.11/site-packages/arviz/stats/stats.py:1645: UserWarning: For one or more samples the posterior variance of the log predictive densities exceeds 0.4. This could be indication of WAIC starting to fail. \n",
      "See http://arxiv.org/abs/1507.04544 for details\n",
      "  warnings.warn(\n",
      "2023-10-27 15:51:59,700 - __main__ - INFO - ELPD WAIC (Log): 9033.36\n"
     ]
    }
   ],
   "source": [
    "numpyro_data = az.from_numpyro(mcmc)\n",
    "\n",
    "\"\"\" Model evaluation \"\"\"\n",
    "logger.info(\"Evaluating model ...\")\n",
    "\n",
    "score = az.loo(numpyro_data)\n",
    "logger.info(f\"ELPD LOO (Log): {score.elpd_loo:.2f}\")\n",
    "\n",
    "score = az.waic(numpyro_data)\n",
    "logger.info(f\"ELPD WAIC (Log): {score.elpd_waic:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "dest = os.path.join(model.build_dir, \"inference.pkl\")\n",
    "with open(dest, \"wb\") as f:\n",
    "    pickle.dump((model, mcmc, posterior_samples), f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/vishu/repos/hbmep-paper/reports/paper/tms/link-comparison/rectified_logistic/numpyro_data.nc'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dest = os.path.join(model.build_dir, \"numpyro_data.nc\")\n",
    "az.to_netcdf(numpyro_data, dest)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
