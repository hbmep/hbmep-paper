{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os\n",
    "import pickle\n",
    "import logging\n",
    "import multiprocessing\n",
    "from pathlib import Path\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "\n",
    "import arviz as az\n",
    "import numpyro\n",
    "\n",
    "from hbmep.config import Config\n",
    "from hbmep.model.utils import Site as site\n",
    "\n",
    "PLATFORM = \"cpu\"\n",
    "jax.config.update(\"jax_platforms\", PLATFORM)\n",
    "numpyro.set_platform(PLATFORM)\n",
    "\n",
    "cpu_count = multiprocessing.cpu_count() - 2\n",
    "numpyro.set_host_device_count(cpu_count)\n",
    "numpyro.enable_x64()\n",
    "numpyro.enable_validation()\n",
    "\n",
    "logger = logging.getLogger(__name__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpyro.distributions as dist\n",
    "from hbmep.model import BaseModel\n",
    "\n",
    "\n",
    "class MixtureModel(BaseModel):\n",
    "    LINK = \"mixture_model\"\n",
    "\n",
    "    def __init__(self, config: Config):\n",
    "        super(MixtureModel, self).__init__(config=config)\n",
    "        self.combination_columns = self.features + [self.subject]\n",
    "\n",
    "    def fn(self, x, a, b, v, L, ell, H):\n",
    "        return (\n",
    "            L\n",
    "            + jnp.where(\n",
    "                jnp.less(x, a),\n",
    "                0.,\n",
    "                -ell + jnp.true_divide(\n",
    "                    H + ell,\n",
    "                    jnp.power(\n",
    "                        1\n",
    "                        + jnp.multiply(\n",
    "                            -1\n",
    "                            + jnp.power(\n",
    "                                jnp.true_divide(H + ell, ell),\n",
    "                                v\n",
    "                            ),\n",
    "                            jnp.exp(jnp.multiply(-b, x - a))\n",
    "                        ),\n",
    "                        jnp.true_divide(1, v)\n",
    "                    )\n",
    "                )\n",
    "            )\n",
    "        )\n",
    "\n",
    "    def _model(self, subject, features, intensity, response_obs=None):\n",
    "        subject, n_subject = subject\n",
    "        features, n_features = features\n",
    "        intensity, n_data = intensity\n",
    "\n",
    "        intensity = intensity.reshape(-1, 1)\n",
    "        intensity = np.tile(intensity, (1, self.n_response))\n",
    "\n",
    "        feature0 = features[0].reshape(-1,)\n",
    "        n_feature0 = n_features[0]\n",
    "\n",
    "        with numpyro.plate(site.n_response, self.n_response):\n",
    "            \"\"\" Global Priors \"\"\"\n",
    "            # a_mean_global_scale = numpyro.sample(\"a_mean_global_scale\", dist.HalfNormal(50))\n",
    "            # a_shape_global_scale = numpyro.sample(\"a_shape_global_scale\", dist.HalfNormal(1))\n",
    "\n",
    "            b_scale_global_scale = numpyro.sample(\"b_scale_global_scale\", dist.HalfNormal(100))\n",
    "            v_scale_global_scale = numpyro.sample(\"v_scale_global_scale\", dist.HalfNormal(100))\n",
    "\n",
    "            L_scale_global_scale = numpyro.sample(\"L_scale_global_scale\", dist.HalfNormal(10))\n",
    "            ell_scale_global_scale = numpyro.sample(\"ell_scale_global_scale\", dist.HalfNormal(100))\n",
    "            H_scale_global_scale = numpyro.sample(\"H_scale_global_scale\", dist.HalfNormal(10))\n",
    "\n",
    "            g_1_scale_global_scale = numpyro.sample(\"g_1_scale_global_scale\", dist.HalfNormal(100))\n",
    "            g_2_scale_global_scale = numpyro.sample(\"g_2_scale_global_scale\", dist.HalfNormal(100))\n",
    "\n",
    "            with numpyro.plate(\"n_feature0\", n_feature0):\n",
    "                \"\"\" Hyper-priors \"\"\"\n",
    "                # a_mean_raw = numpyro.sample(\"a_mean_raw\", dist.HalfNormal(scale=1))\n",
    "                # a_mean = numpyro.deterministic(\"a_mean\", jnp.multiply(a_mean_global_scale, a_mean_raw))\n",
    "                a_mean = numpyro.sample(\"a_mean\", dist.TruncatedNormal(loc=50, scale=50, low=0))\n",
    "                a_scale = numpyro.sample(\"a_scale\", dist.HalfNormal(scale=100))\n",
    "\n",
    "                # a_shape_raw = numpyro.sample(\"a_shape_raw\", dist.HalfNormal(scale=1))\n",
    "                # a_shape = numpyro.deterministic(\"a_shape\", jnp.multiply(a_shape_global_scale, a_shape_raw))\n",
    "\n",
    "                b_scale_raw = numpyro.sample(\"b_scale_raw\", dist.HalfNormal(scale=1))\n",
    "                b_scale = numpyro.deterministic(\"b_scale\", jnp.multiply(b_scale_global_scale, b_scale_raw))\n",
    "\n",
    "                v_scale_raw = numpyro.sample(\"v_scale_raw\", dist.HalfNormal(scale=1))\n",
    "                v_scale = numpyro.deterministic(\"v_scale\", jnp.multiply(v_scale_global_scale, v_scale_raw))\n",
    "\n",
    "                L_scale_raw = numpyro.sample(\"L_scale_raw\", dist.HalfNormal(scale=1))\n",
    "                L_scale = numpyro.deterministic(\"L_scale\", jnp.multiply(L_scale_global_scale, L_scale_raw))\n",
    "\n",
    "                ell_scale_raw = numpyro.sample(\"ell_scale_raw\", dist.HalfNormal(scale=1))\n",
    "                ell_scale = numpyro.deterministic(\"sigma_ell\", jnp.multiply(ell_scale_global_scale, ell_scale_raw))\n",
    "\n",
    "                H_scale_raw = numpyro.sample(\"H_scale_raw\", dist.HalfNormal(scale=1))\n",
    "                H_scale = numpyro.deterministic(\"H_scale\", jnp.multiply(H_scale_global_scale, H_scale_raw))\n",
    "\n",
    "                g_1_scale_raw = numpyro.sample(\"g_1_scale_raw\", dist.HalfNormal(scale=1))\n",
    "                g_1_scale = numpyro.deterministic(\"g_1_scale\", jnp.multiply(g_1_scale_global_scale, g_1_scale_raw))\n",
    "\n",
    "                g_2_scale_raw = numpyro.sample(\"g_2_scale_raw\", dist.HalfNormal(scale=1))\n",
    "                g_2_scale = numpyro.deterministic(\"g_2_scale\", jnp.multiply(g_2_scale_global_scale, g_2_scale_raw))\n",
    "\n",
    "                with numpyro.plate(site.n_subject, n_subject):\n",
    "                    \"\"\" Priors \"\"\"\n",
    "                    # a_raw = numpyro.sample(\"a_raw\", dist.Gamma(concentration=a_shape, rate=1))\n",
    "                    # a = numpyro.deterministic(site.a, jnp.true_divide(jnp.multiply(a_raw, a_mean), a_shape))\n",
    "                    a = numpyro.sample(site.a, dist.TruncatedNormal(loc=a_mean, scale=a_scale, low=0))\n",
    "\n",
    "                    b_raw = numpyro.sample(\"b_raw\", dist.HalfNormal(scale=1))\n",
    "                    b = numpyro.deterministic(site.b, jnp.multiply(b_scale, b_raw))\n",
    "\n",
    "                    v_raw = numpyro.sample(\"v_raw\", dist.HalfNormal(scale=1))\n",
    "                    v = numpyro.deterministic(site.v, jnp.multiply(v_scale, v_raw))\n",
    "\n",
    "                    L_raw = numpyro.sample(\"L_raw\", dist.HalfNormal(scale=1))\n",
    "                    L = numpyro.deterministic(site.L, jnp.multiply(L_scale, L_raw))\n",
    "\n",
    "                    ell_raw = numpyro.sample(\"ell_raw\", dist.HalfNormal(scale=1))\n",
    "                    ell = numpyro.deterministic(\"ell\", jnp.multiply(ell_scale, ell_raw))\n",
    "\n",
    "                    H_raw = numpyro.sample(\"H_raw\", dist.HalfNormal(scale=1))\n",
    "                    H = numpyro.deterministic(site.H, jnp.multiply(H_scale, H_raw))\n",
    "\n",
    "                    g_1_raw = numpyro.sample(\"g_1_raw\", dist.HalfCauchy(scale=1))\n",
    "                    g_1 = numpyro.deterministic(site.g_1, jnp.multiply(g_1_scale, g_1_raw))\n",
    "\n",
    "                    g_2_raw = numpyro.sample(\"g_2_raw\", dist.HalfCauchy(scale=1))\n",
    "                    g_2 = numpyro.deterministic(site.g_2, jnp.multiply(g_2_scale, g_2_raw))\n",
    "\n",
    "                    penalty_for_small_a = jnp.true_divide(1, a)\n",
    "                    numpyro.factor(\"penalty_for_small_a\", -penalty_for_small_a)\n",
    "\n",
    "                    # penalty_for_small_b = jnp.true_divide(1, b)\n",
    "                    # numpyro.factor(\"penalty_for_small_b\", -penalty_for_small_b)\n",
    "\n",
    "                    # penalty_for_small_H = jnp.true_divide(1, H)\n",
    "                    # numpyro.factor(\"penalty_for_small_H\", -penalty_for_small_H)\n",
    "\n",
    "\n",
    "        \"\"\" Outlier Distribution \"\"\"\n",
    "        outlier_prob = numpyro.sample(\"outlier_prob\", dist.Uniform(0., .05))\n",
    "        outlier_scale = numpyro.sample(\"outlier_scale\", dist.HalfNormal(5))\n",
    "\n",
    "        with numpyro.plate(site.n_response, self.n_response):\n",
    "            with numpyro.plate(site.n_data, n_data):\n",
    "                \"\"\" Model \"\"\"\n",
    "                mu = numpyro.deterministic(\n",
    "                    site.mu,\n",
    "                    self.fn(\n",
    "                        x=intensity,\n",
    "                        a=a[subject, feature0],\n",
    "                        b=b[subject, feature0],\n",
    "                        v=v[subject, feature0],\n",
    "                        L=L[subject, feature0],\n",
    "                        ell=ell[subject, feature0],\n",
    "                        H=H[subject, feature0]\n",
    "                    )\n",
    "                )\n",
    "                beta = numpyro.deterministic(\n",
    "                    site.beta,\n",
    "                    g_1[subject, feature0] + jnp.true_divide(g_2[subject, feature0], mu)\n",
    "                )\n",
    "\n",
    "                q = numpyro.deterministic(\"q\", outlier_prob * jnp.ones((n_data, self.n_response)))\n",
    "                bg_scale = numpyro.deterministic(\"bg_scale\", outlier_scale * jnp.ones((n_data, self.n_response)))\n",
    "\n",
    "                mixing_distribution = dist.Categorical(\n",
    "                    probs=jnp.stack([1 - q, q], axis=-1)\n",
    "                )\n",
    "                component_distributions=[\n",
    "                    dist.Gamma(concentration=jnp.multiply(mu, beta), rate=beta),\n",
    "                    dist.HalfNormal(scale=bg_scale)\n",
    "                ]\n",
    "\n",
    "                \"\"\" Mixture \"\"\"\n",
    "                Mixture = dist.MixtureGeneral(\n",
    "                    mixing_distribution=mixing_distribution,\n",
    "                    component_distributions=component_distributions\n",
    "                )\n",
    "\n",
    "                \"\"\" Observation \"\"\"\n",
    "                numpyro.sample(\n",
    "                    site.obs,\n",
    "                    Mixture,\n",
    "                    obs=response_obs\n",
    "                )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-16 12:34:38,841 - hbmep.config - INFO - Verifying configuration ...\n",
      "2023-11-16 12:34:38,841 - hbmep.config - INFO - Success!\n",
      "2023-11-16 12:34:38,862 - hbmep.model.baseline - INFO - Initialized base_model\n"
     ]
    }
   ],
   "source": [
    "toml_path = \"/home/vishu/repos/hbmep-paper/configs/paper/tms/proc-2023-11-13/config.toml\"\n",
    "\n",
    "config = Config(toml_path=toml_path)\n",
    "config.BUILD_DIR = os.path.join(config.BUILD_DIR, \"model-comparison/mixture-model/outlier-about-curve/penalty\")\n",
    "config.RESPONSE = [\"PKPK_ADM\"]\n",
    "\n",
    "config.MCMC_PARAMS[\"num_warmup\"] = 1000\n",
    "config.MCMC_PARAMS[\"num_samples\"] = 1000\n",
    "\n",
    "model = MixtureModel(config=config)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-16 12:34:38,953 - hbmep.dataset.core - INFO - Artefacts will be stored here - /home/vishu/repos/hbmep-paper/reports/paper/tms/proc-2023-11-13/model-comparison/mixture-model/outlier-about-curve/penalty\n",
      "2023-11-16 12:34:38,954 - hbmep.dataset.core - INFO - Copied config to /home/vishu/repos/hbmep-paper/reports/paper/tms/proc-2023-11-13/model-comparison/mixture-model/outlier-about-curve/penalty\n",
      "2023-11-16 12:34:38,955 - hbmep.dataset.core - INFO - Processing data ...\n",
      "2023-11-16 12:34:38,957 - hbmep.utils.utils - INFO - func:load took: 0.00 sec\n"
     ]
    }
   ],
   "source": [
    "src = \"/home/vishu/data/hbmep-processed/human/tms/proc-2023-11-15.csv\"\n",
    "df = pd.read_csv(src)\n",
    "\n",
    "df[model.features[0]] = df[model.features[0]].replace({\n",
    "    \"Uninjured\": \"01_Uninjured\",\n",
    "    \"SCI\": \"02_SCI\"\n",
    "})\n",
    "\n",
    "# subset = [\"SCS04\", \"SCS06\", \"SCS03\"]\n",
    "# ind = df[model.subject].isin(subset)\n",
    "# df = df[ind].reset_index(drop=True).copy()\n",
    "\n",
    "ind = df[model.intensity] > 0\n",
    "df = df[ind].reset_index(drop=True).copy()\n",
    "\n",
    "df, encoder_dict = model.load(df=df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-16 12:34:39,017 - hbmep.model.baseline - INFO - Running inference with base_model ...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "646bf24c5e68494aa69e9d0f1d4883e4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4ff5f3a5fff34f3daa359fc4e006b283",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2b3a5cc49eb34f6b8148473918cb9c89",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a194f3e6d37347eea2231697d350649f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-16 12:45:17,491 - hbmep.utils.utils - INFO - func:run_inference took: 10 min and 38.47 sec\n"
     ]
    }
   ],
   "source": [
    "mcmc, posterior_samples = model.run_inference(df=df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-16 12:57:16,056 - hbmep.utils.utils - INFO - func:make_prediction_dataset took: 0.00 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-16 12:57:19,622 - hbmep.utils.utils - INFO - func:predict took: 3.57 sec\n",
      "2023-11-16 12:57:19,623 - hbmep.model.baseline - INFO - Rendering recruitment curves ...\n",
      "2023-11-16 12:57:22,572 - hbmep.model.baseline - INFO - Saved to /home/vishu/repos/hbmep-paper/reports/paper/tms/proc-2023-11-13/model-comparison/mixture-model/outlier-about-curve/penalty/recruitment_curves.pdf\n",
      "2023-11-16 12:57:22,572 - hbmep.utils.utils - INFO - func:render_recruitment_curves took: 2.95 sec\n",
      "2023-11-16 12:57:22,572 - hbmep.model.baseline - INFO - Rendering posterior predictive checks ...\n",
      "2023-11-16 12:57:26,056 - hbmep.model.baseline - INFO - Saved to /home/vishu/repos/hbmep-paper/reports/paper/tms/proc-2023-11-13/model-comparison/mixture-model/outlier-about-curve/penalty/posterior_predictive_check.pdf\n",
      "2023-11-16 12:57:26,057 - hbmep.utils.utils - INFO - func:predictive_checks_renderer took: 3.48 sec\n",
      "2023-11-16 12:57:26,057 - hbmep.utils.utils - INFO - func:render_predictive_check took: 3.48 sec\n"
     ]
    }
   ],
   "source": [
    "_posterior_samples = posterior_samples.copy()\n",
    "_posterior_samples[\"outlier_prob\"] = _posterior_samples[\"outlier_prob\"] * 0\n",
    "\n",
    "prediction_df = model.make_prediction_dataset(df=df)\n",
    "posterior_predictive = model.predict(df=prediction_df, posterior_samples=_posterior_samples)\n",
    "\n",
    "model.render_recruitment_curves(df=df, encoder_dict=encoder_dict, posterior_samples=_posterior_samples, prediction_df=prediction_df, posterior_predictive=posterior_predictive)\n",
    "model.render_predictive_check(df=df, encoder_dict=encoder_dict, prediction_df=prediction_df, posterior_predictive=posterior_predictive)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TtestResult(statistic=-1.7573273478705749, pvalue=0.049623446495908205, df=15.0)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import scipy.stats as stats\n",
    "\n",
    "a = posterior_samples[\"a\"]\n",
    "a_map = a.mean(axis=0)\n",
    "\n",
    "\n",
    "stats.ttest_ind(\n",
    "    a=a_map[:10, 0, 0], b=a_map[10:, 1, 0], alternative=\"less\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-16 12:30:13,808 - __main__ - INFO - Evaluating model ...\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "Found several log likelihood arrays ['obs', 'penalty_for_small_a'], var_name cannot be None",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/home/vishu/repos/hbmep-paper/notebooks/paper/tms/model-comparison/outlier-about-curve/penalty.ipynb Cell 7\u001b[0m line \u001b[0;36m6\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bcumc00/home/vishu/repos/hbmep-paper/notebooks/paper/tms/model-comparison/outlier-about-curve/penalty.ipynb#X11sdnNjb2RlLXJlbW90ZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39m\"\"\" Model evaluation \"\"\"\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bcumc00/home/vishu/repos/hbmep-paper/notebooks/paper/tms/model-comparison/outlier-about-curve/penalty.ipynb#X11sdnNjb2RlLXJlbW90ZQ%3D%3D?line=3'>4</a>\u001b[0m logger\u001b[39m.\u001b[39minfo(\u001b[39m\"\u001b[39m\u001b[39mEvaluating model ...\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2Bcumc00/home/vishu/repos/hbmep-paper/notebooks/paper/tms/model-comparison/outlier-about-curve/penalty.ipynb#X11sdnNjb2RlLXJlbW90ZQ%3D%3D?line=5'>6</a>\u001b[0m score \u001b[39m=\u001b[39m az\u001b[39m.\u001b[39;49mloo(numpyro_data)\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bcumc00/home/vishu/repos/hbmep-paper/notebooks/paper/tms/model-comparison/outlier-about-curve/penalty.ipynb#X11sdnNjb2RlLXJlbW90ZQ%3D%3D?line=6'>7</a>\u001b[0m logger\u001b[39m.\u001b[39minfo(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mELPD LOO (Log): \u001b[39m\u001b[39m{\u001b[39;00mscore\u001b[39m.\u001b[39melpd_loo\u001b[39m:\u001b[39;00m\u001b[39m.2f\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bcumc00/home/vishu/repos/hbmep-paper/notebooks/paper/tms/model-comparison/outlier-about-curve/penalty.ipynb#X11sdnNjb2RlLXJlbW90ZQ%3D%3D?line=8'>9</a>\u001b[0m score \u001b[39m=\u001b[39m az\u001b[39m.\u001b[39mwaic(numpyro_data)\n",
      "File \u001b[0;32m~/repos/hbmep-paper/.venv/lib/python3.11/site-packages/arviz/stats/stats.py:766\u001b[0m, in \u001b[0;36mloo\u001b[0;34m(data, pointwise, var_name, reff, scale)\u001b[0m\n\u001b[1;32m    693\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Compute Pareto-smoothed importance sampling leave-one-out cross-validation (PSIS-LOO-CV).\u001b[39;00m\n\u001b[1;32m    694\u001b[0m \n\u001b[1;32m    695\u001b[0m \u001b[39mEstimates the expected log pointwise predictive density (elpd) using Pareto-smoothed\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    763\u001b[0m \u001b[39m       ...: data_loo.loo_i\u001b[39;00m\n\u001b[1;32m    764\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    765\u001b[0m inference_data \u001b[39m=\u001b[39m convert_to_inference_data(data)\n\u001b[0;32m--> 766\u001b[0m log_likelihood \u001b[39m=\u001b[39m _get_log_likelihood(inference_data, var_name\u001b[39m=\u001b[39;49mvar_name)\n\u001b[1;32m    767\u001b[0m pointwise \u001b[39m=\u001b[39m rcParams[\u001b[39m\"\u001b[39m\u001b[39mstats.ic_pointwise\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39mif\u001b[39;00m pointwise \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m pointwise\n\u001b[1;32m    769\u001b[0m log_likelihood \u001b[39m=\u001b[39m log_likelihood\u001b[39m.\u001b[39mstack(__sample__\u001b[39m=\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mchain\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mdraw\u001b[39m\u001b[39m\"\u001b[39m))\n",
      "File \u001b[0;32m~/repos/hbmep-paper/.venv/lib/python3.11/site-packages/arviz/stats/stats_utils.py:429\u001b[0m, in \u001b[0;36mget_log_likelihood\u001b[0;34m(idata, var_name)\u001b[0m\n\u001b[1;32m    427\u001b[0m     var_names \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(idata\u001b[39m.\u001b[39mlog_likelihood\u001b[39m.\u001b[39mdata_vars)\n\u001b[1;32m    428\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(var_names) \u001b[39m>\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[0;32m--> 429\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mTypeError\u001b[39;00m(\n\u001b[1;32m    430\u001b[0m             \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mFound several log likelihood arrays \u001b[39m\u001b[39m{\u001b[39;00mvar_names\u001b[39m}\u001b[39;00m\u001b[39m, var_name cannot be None\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    431\u001b[0m         )\n\u001b[1;32m    432\u001b[0m     \u001b[39mreturn\u001b[39;00m idata\u001b[39m.\u001b[39mlog_likelihood[var_names[\u001b[39m0\u001b[39m]]\n\u001b[1;32m    433\u001b[0m \u001b[39melse\u001b[39;00m:\n",
      "\u001b[0;31mTypeError\u001b[0m: Found several log likelihood arrays ['obs', 'penalty_for_small_a'], var_name cannot be None"
     ]
    }
   ],
   "source": [
    "numpyro_data = az.from_numpyro(mcmc)\n",
    "\n",
    "\"\"\" Model evaluation \"\"\"\n",
    "logger.info(\"Evaluating model ...\")\n",
    "\n",
    "score = az.loo(numpyro_data)\n",
    "logger.info(f\"ELPD LOO (Log): {score.elpd_loo:.2f}\")\n",
    "\n",
    "score = az.waic(numpyro_data)\n",
    "logger.info(f\"ELPD WAIC (Log): {score.elpd_waic:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[0.06199351]],\n",
       "\n",
       "       [[0.45610779]]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "posterior_samples[\"outlier_prob\"].mean(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "                               mean       std    median      2.5%     97.5%     n_eff     r_hat\n",
      "             H_raw[0,0,0]      0.77      0.55      0.67      0.04      1.87    260.66      1.02\n",
      "  H_scale_global_scale[0]      7.27      5.49      6.02      0.23     18.18    193.98      1.02\n",
      "         H_scale_raw[0,0]      0.70      0.53      0.56      0.04      1.77    286.49      1.01\n",
      "             L_raw[0,0,0]      0.32      0.44      0.12      0.00      1.20    256.86      1.02\n",
      "  L_scale_global_scale[0]      3.35      4.33      1.58      0.00     12.47    416.08      1.01\n",
      "         L_scale_raw[0,0]      0.33      0.50      0.12      0.00      1.47     68.08      1.07\n",
      "   a_mean_global_scale[0]     82.37     49.92     70.15     12.54    189.76    187.72      1.02\n",
      "          a_mean_raw[0,0]      0.78      0.45      0.67      0.11      1.63    155.63      1.02\n",
      "             a_raw[0,0,0]     62.10     75.95     36.84      0.07    206.51    172.61      1.01\n",
      "  a_shape_global_scale[0]     78.07     57.90     65.79      0.16    191.15    246.81      1.01\n",
      "         a_shape_raw[0,0]      0.82      0.59      0.76      0.01      1.93    167.87      1.02\n",
      "             b_raw[0,0,0]      0.46      0.49      0.30      0.00      1.46    214.18      1.01\n",
      "  b_scale_global_scale[0]     48.06     47.84     31.97      0.12    147.03    425.57      1.01\n",
      "         b_scale_raw[0,0]      0.48      0.51      0.31      0.00      1.63    223.11      1.01\n",
      "           g_1_raw[0,0,0]      0.90      4.22      0.35      0.00      2.78    695.13      1.01\n",
      "g_1_scale_global_scale[0]     47.48     47.10     33.58      0.01    146.39    306.07      1.01\n",
      "       g_1_scale_raw[0,0]      0.54      0.50      0.37      0.00      1.52    369.25      1.01\n",
      "           g_2_raw[0,0,0]      0.61      0.84      0.33      0.00      2.21    239.99      1.01\n",
      "g_2_scale_global_scale[0]     52.18     49.14     36.36      0.72    152.19    238.39      1.01\n",
      "       g_2_scale_raw[0,0]      0.51      0.50      0.35      0.00      1.55    332.65      1.01\n",
      "             l_raw[0,0,0]      0.44      0.52      0.24      0.00      1.48    152.43      1.03\n",
      "  l_scale_global_scale[0]     41.36     48.35     24.19      0.00    140.23    210.77      1.00\n",
      "         l_scale_raw[0,0]      0.42      0.49      0.24      0.00      1.43    216.53      1.03\n",
      "      outlier_prob[0,0,0]      0.11      0.06      0.11      0.02      0.20     55.05      1.08\n",
      "        outlier_rate[0,0]      3.22      1.96      2.97      0.09      6.38    170.64      1.03\n",
      "             v_raw[0,0,0]      0.89      0.59      0.79      0.04      2.05    255.62      1.02\n",
      "  v_scale_global_scale[0]     93.15     60.54     83.25      3.92    214.91    207.59      1.02\n",
      "         v_scale_raw[0,0]      0.90      0.58      0.78      0.02      2.03    323.08      1.02\n",
      "\n",
      "Number of divergences: 1802\n"
     ]
    }
   ],
   "source": [
    "mcmc.print_summary(prob=.95)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "dest = os.path.join(model.build_dir, \"inference.pkl\")\n",
    "with open(dest, \"wb\") as f:\n",
    "    pickle.dump((model, mcmc, posterior_samples), f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
