{"cells":[{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[],"source":["import os\n","import pickle\n","import logging"]},{"cell_type":"code","execution_count":2,"metadata":{},"outputs":[],"source":["import numpy as np\n","import pandas as pd\n","from joblib import Parallel, delayed"]},{"cell_type":"code","execution_count":3,"metadata":{},"outputs":[],"source":["import arviz as az\n","import matplotlib.pyplot as plt\n","import seaborn as sns"]},{"cell_type":"code","execution_count":4,"metadata":{},"outputs":[],"source":["from hbmep.config import Config\n","from hbmep.model.utils import Site as site"]},{"cell_type":"code","execution_count":5,"metadata":{},"outputs":[],"source":["from hbmep_paper.utils import setup_logging, run_svi\n","from models import (\n","    # MixtureModel,\n","    RectifiedLogistic,\n","    Logistic5,\n","    Logistic4,\n","    ReLU\n",")"]},{"cell_type":"code","execution_count":6,"metadata":{},"outputs":[],"source":["logger = logging.getLogger(__name__)\n","LEVEL = logging.INFO"]},{"cell_type":"code","execution_count":7,"metadata":{},"outputs":[],"source":["TOML_PATH = \"/home/vishu/repos/hbmep-paper/configs/rats/J_RCML_000.toml\"\n","DATA_PATH = \"/home/vishu/data/hbmep-processed/J_RCML_000/data.csv\"\n","FEATURES = [[\"participant\", \"compound_position\"]]\n","# FEATURES = [\"participant\", \"compound_position\"]\n","RESPONSE = [\"LBiceps\", \"LECR\"]\n","BUILD_DIR = \"/home/vishu/repos/hbmep-paper/reports/tms/fn-comparison/testing\"\n"]},{"cell_type":"code","execution_count":8,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["2024-02-19 11:22:03,326 - hbmep_paper.utils.utils - INFO - Logging to /home/vishu/repos/hbmep-paper/reports/tms/fn-comparison/testing/rectified_logistic/loo-debug.log\n"]}],"source":["# Run single model\n","# Model = ReLU\n","# Model = Logistic4\n","Model = Logistic5\n","Model = RectifiedLogistic\n","\n","# # Run multiple models in parallel\n","# n_jobs = -1\n","# models = [RectifiedLogistic, Logistic5, Logistic4, ReLU]\n","# with Parallel(n_jobs=n_jobs) as parallel:\n","#     parallel(delayed(main)(Model) for Model in models)\n","\n","# Build model\n","config = Config(toml_path=TOML_PATH)\n","config.FEATURES = FEATURES\n","config.RESPONSE = RESPONSE\n","config.BUILD_DIR = os.path.join(BUILD_DIR, Model.NAME)\n","config.MCMC_PARAMS[\"num_warmup\"] = 5000\n","config.MCMC_PARAMS[\"num_samples\"] = 1000\n","model = Model(config=config)\n","\n","# Setup logging\n","model._make_dir(config.BUILD_DIR)\n","setup_logging(\n","    dir=model.build_dir,\n","    fname=os.path.basename(\"loo-debug\"),\n","    level=LEVEL\n",")\n","\n","# Run inference\n","# run_inference(model)\n","# return"]},{"cell_type":"code","execution_count":10,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["2024-02-19 11:22:08,789 - hbmep.dataset.core - INFO - Artefacts will be stored here - /home/vishu/repos/hbmep-paper/reports/tms/fn-comparison/testing/rectified_logistic\n","2024-02-19 11:22:08,800 - hbmep.dataset.core - INFO - Processing data ...\n","2024-02-19 11:22:08,802 - hbmep.utils.utils - INFO - func:load took: 0.01 sec\n","2024-02-19 11:22:08,803 - hbmep.model.baseline - INFO - Running inference with rectified_logistic ...\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"5d547ef947d94d12822b75e34a8a9df6","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/6000 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"64bab17ce2834a589342d1d0c029e873","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/6000 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"e5f1d5ed0f27412ca8f8fd666750a51b","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/6000 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"be9935ac4b3e4ad9adb41be31a45c908","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/6000 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["2024-02-19 11:23:01,135 - hbmep.utils.utils - INFO - func:run_inference took: 52.33 sec\n","2024-02-19 11:23:01,139 - hbmep.utils.utils - INFO - func:make_prediction_dataset took: 0.00 sec\n","2024-02-19 11:23:02,185 - hbmep.utils.utils - INFO - func:predict took: 1.04 sec\n","2024-02-19 11:23:02,185 - hbmep.plotter.core - INFO - Rendering recruitment curves ...\n","2024-02-19 11:23:02,933 - hbmep.plotter.core - INFO - Saved to /home/vishu/repos/hbmep-paper/reports/tms/fn-comparison/testing/rectified_logistic/recruitment_curves.pdf\n","2024-02-19 11:23:02,933 - hbmep.utils.utils - INFO - func:render_recruitment_curves took: 0.75 sec\n","2024-02-19 11:23:02,934 - hbmep.plotter.core - INFO - Rendering posterior predictive checks ...\n","2024-02-19 11:23:03,864 - hbmep.plotter.core - INFO - Saved to /home/vishu/repos/hbmep-paper/reports/tms/fn-comparison/testing/rectified_logistic/posterior_predictive_check.pdf\n","2024-02-19 11:23:03,864 - hbmep.utils.utils - INFO - func:predictive_checks_renderer took: 0.93 sec\n","2024-02-19 11:23:03,864 - hbmep.utils.utils - INFO - func:render_predictive_check took: 0.93 sec\n"]}],"source":["# Load data\n","df = pd.read_csv(DATA_PATH)\n","df, encoder_dict = model.load(df=df)\n","ind = df[model.features[0]].isin([0, 1])\n","df = df[ind].reset_index(drop=True).copy()\n","\n","# Run inference\n","mcmc, posterior_samples = model.run_inference(df=df)\n","# svi_results, posterior_samples = run_svi(df=df, model=model, **svi_kwargs)\n","# svi_result, posterior_samples = run_svi(df=df, model=model, steps=20000, lr=1e-2)\n","# if model.NAME == \"rectified_logistic\":\n","#     logger.info(f\"ell: {posterior_samples[site.ell].mean(axis=0)}\")\n","\n","# losses = np.array(svi_result.losses)\n","# plt.plot(losses)\n","# dest = os.path.join(model.build_dir, \"losses.png\")\n","# plt.savefig(dest)\n","# logger.info(f\"Saved to {dest}\")\n","\n","# Predict and render plots\n","prediction_df = model.make_prediction_dataset(df=df)\n","posterior_predictive = model.predict(df=prediction_df, posterior_samples=posterior_samples)\n","model.render_recruitment_curves(df=df, encoder_dict=encoder_dict, posterior_samples=posterior_samples, prediction_df=prediction_df, posterior_predictive=posterior_predictive)\n","model.render_predictive_check(df=df, encoder_dict=encoder_dict, prediction_df=prediction_df, posterior_predictive=posterior_predictive)\n","\n"]},{"cell_type":"code","execution_count":11,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["2024-02-19 09:50:20,694 - __main__ - INFO - intensity: (20, 1)\n","2024-02-19 09:50:20,695 - __main__ - INFO - features: (20, 1)\n","2024-02-19 09:50:20,695 - __main__ - INFO - response: (20, 2)\n"]}],"source":["from numpyro.infer.util import log_density\n","intensity, features = model._get_regressors(df)\n","response, = model._get_response(df)\n","intensity = intensity[:20, ...]\n","features = features[:20, ...]\n","response = response[:20, ...]\n","logger.info(f\"intensity: {intensity.shape}\")\n","logger.info(f\"features: {features.shape}\")\n","logger.info(f\"response: {response.shape}\")\n"]},{"cell_type":"code","execution_count":64,"metadata":{},"outputs":[{"data":{"text/plain":["Array(299.8246208, dtype=float64)"]},"execution_count":64,"metadata":{},"output_type":"execute_result"}],"source":["from numpyro import handlers\n","from jax import vmap\n","from jax import random\n","from jax.scipy.special import logsumexp\n","import jax.numpy as jnp\n","\n","\n","def log_likelihood(rng_key, params, model, *args, **kwargs):\n","    model = handlers.condition(model, params)\n","    # model = handlers.substitute(model, params)\n","    model_trace = handlers.trace(model).get_trace(*args, **kwargs)\n","    obs_node = model_trace[\"obs\"]\n","    return obs_node[\"fn\"].log_prob(obs_node[\"value\"])\n","\n","\n","def log_pred_density(rng_key, params, model, *args, **kwargs):\n","    n = list(params.values())[0].shape[0]\n","    log_lk_fn = vmap(\n","        lambda rng_key, params: log_likelihood(rng_key, params, model, *args, **kwargs)\n","    )\n","    log_lk_vals = log_lk_fn(random.split(rng_key, n), params)\n","    return (logsumexp(log_lk_vals, 0) - jnp.log(n)).sum()\n","\n","_posterior_samples = posterior_samples.copy()\n","_posterior_samples[site.alpha] = 0 * _posterior_samples[site.alpha]\n","_posterior_samples[site.mu] = 0 * _posterior_samples[site.mu]\n","_posterior_samples[site.beta] = 0 * _posterior_samples[site.beta]\n","log_pred_density(\n","    random.PRNGKey(2),\n","    _posterior_samples,\n","    model._model,\n","    *model._get_regressors(df),\n","    *model._get_response(df),\n",")\n"]},{"cell_type":"code","execution_count":35,"metadata":{},"outputs":[],"source":["m = handlers.condition(model._model, {u: v[0, ...] for u, v in posterior_samples.items()})\n"]},{"cell_type":"code","execution_count":38,"metadata":{},"outputs":[{"data":{"text/plain":["collections.OrderedDict"]},"execution_count":38,"metadata":{},"output_type":"execute_result"}],"source":["trace = handlers.trace(m).get_trace(*model._get_regressors(df), *model._get_response(df))\n","type(trace)"]},{"cell_type":"code","execution_count":51,"metadata":{},"outputs":[{"data":{"text/plain":["array([[False, False],\n","       [False, False]])"]},"execution_count":51,"metadata":{},"output_type":"execute_result"}],"source":["trace[site.a][\"value\"] == posterior_samples[site.b][0, ...]"]},{"cell_type":"code","execution_count":19,"metadata":{},"outputs":[{"data":{"text/plain":["Array(299.8246208, dtype=float64)"]},"execution_count":19,"metadata":{},"output_type":"execute_result"}],"source":["# ind = df[model.features[0]].isin([1])\n","\n","log_pred_density(\n","    random.PRNGKey(2),\n","    posterior_samples,\n","    model._model,\n","    *model._get_regressors(df),\n","    *model._get_response(df)\n",")\n","\n"]},{"cell_type":"code","execution_count":15,"metadata":{},"outputs":[],"source":["ind = df[model.intensity] < 62\n","df = df[ind].reset_index(drop=True).copy()"]},{"cell_type":"code","execution_count":17,"metadata":{},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>pulse_amplitude</th>\n","      <th>pulse_train_frequency</th>\n","      <th>pulse_period</th>\n","      <th>pulse_duration</th>\n","      <th>pulse_count</th>\n","      <th>train_delay</th>\n","      <th>channel1_1</th>\n","      <th>channel1_2</th>\n","      <th>channel1_3</th>\n","      <th>channel1_4</th>\n","      <th>...</th>\n","      <th>channel1_laterality</th>\n","      <th>channel1_segment</th>\n","      <th>channel2_laterality</th>\n","      <th>channel2_segment</th>\n","      <th>compound_position</th>\n","      <th>compound_charge_params</th>\n","      <th>participant</th>\n","      <th>subdir_pattern</th>\n","      <th>charge_param_error</th>\n","      <th>participant___compound_position</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>50</td>\n","      <td>0.5</td>\n","      <td>1</td>\n","      <td>0.4</td>\n","      <td>1</td>\n","      <td>2</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>...</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>M</td>\n","      <td>C5</td>\n","      <td>-C5M</td>\n","      <td>50-0-50-100</td>\n","      <td>amap01</td>\n","      <td>*J_RCML_000*</td>\n","      <td>NaN</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>50</td>\n","      <td>0.5</td>\n","      <td>1</td>\n","      <td>0.4</td>\n","      <td>1</td>\n","      <td>2</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>...</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>L</td>\n","      <td>C5</td>\n","      <td>-C5L</td>\n","      <td>50-0-50-100</td>\n","      <td>amap01</td>\n","      <td>*J_RCML_000*</td>\n","      <td>NaN</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>56</td>\n","      <td>0.5</td>\n","      <td>1</td>\n","      <td>0.4</td>\n","      <td>1</td>\n","      <td>2</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>...</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>L</td>\n","      <td>C5</td>\n","      <td>-C5L</td>\n","      <td>50-0-50-100</td>\n","      <td>amap01</td>\n","      <td>*J_RCML_000*</td>\n","      <td>NaN</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>56</td>\n","      <td>0.5</td>\n","      <td>1</td>\n","      <td>0.4</td>\n","      <td>1</td>\n","      <td>2</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>...</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>M</td>\n","      <td>C5</td>\n","      <td>-C5M</td>\n","      <td>50-0-50-100</td>\n","      <td>amap01</td>\n","      <td>*J_RCML_000*</td>\n","      <td>NaN</td>\n","      <td>1</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>4 rows × 45 columns</p>\n","</div>"],"text/plain":["   pulse_amplitude  pulse_train_frequency  pulse_period  pulse_duration  \\\n","0               50                    0.5             1             0.4   \n","1               50                    0.5             1             0.4   \n","2               56                    0.5             1             0.4   \n","3               56                    0.5             1             0.4   \n","\n","   pulse_count  train_delay  channel1_1  channel1_2  channel1_3  channel1_4  \\\n","0            1            2           0           0           0           0   \n","1            1            2           0           0           0           0   \n","2            1            2           0           0           0           0   \n","3            1            2           0           0           0           0   \n","\n","   ...  channel1_laterality  channel1_segment  channel2_laterality  \\\n","0  ...                  NaN               NaN                    M   \n","1  ...                  NaN               NaN                    L   \n","2  ...                  NaN               NaN                    L   \n","3  ...                  NaN               NaN                    M   \n","\n","   channel2_segment  compound_position  compound_charge_params  participant  \\\n","0                C5               -C5M             50-0-50-100       amap01   \n","1                C5               -C5L             50-0-50-100       amap01   \n","2                C5               -C5L             50-0-50-100       amap01   \n","3                C5               -C5M             50-0-50-100       amap01   \n","\n","   subdir_pattern  charge_param_error  participant___compound_position  \n","0    *J_RCML_000*                 NaN                                1  \n","1    *J_RCML_000*                 NaN                                0  \n","2    *J_RCML_000*                 NaN                                0  \n","3    *J_RCML_000*                 NaN                                1  \n","\n","[4 rows x 45 columns]"]},"execution_count":17,"metadata":{},"output_type":"execute_result"}],"source":["df"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["from sklearn.model_selection import KFold\n"]},{"cell_type":"code","execution_count":65,"metadata":{},"outputs":[{"data":{"text/plain":["participant___compound_position\n","0    10\n","1    10\n","dtype: int64"]},"execution_count":65,"metadata":{},"output_type":"execute_result"}],"source":["k = 5\n","\n","(\n","    df\n","    .groupby(by=model.features)\n","    .apply(lambda x: x.sample(frac=1, random_state=0))\n","    .reset_index(drop=True)\n","    .groupby(by=model.features)\n","    .apply(lambda x: (x.shape[0] // k))\n",")\n"]},{"cell_type":"code","execution_count":16,"metadata":{},"outputs":[{"data":{"text/plain":["Array(299.8246208, dtype=float64)"]},"execution_count":16,"metadata":{},"output_type":"execute_result"}],"source":["log_pred_density(\n","    random.PRNGKey(2),\n","    posterior_samples,\n","    model._model,\n","    *model._get_regressors(df),\n","    *model._get_response(df),\n",")\n"]},{"cell_type":"code","execution_count":13,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["/home/vishu/repos/hbmep-paper/.venv/lib/python3.11/site-packages/arviz/stats/stats.py:803: UserWarning: Estimated shape parameter of Pareto distribution is greater than 0.7 for one or more samples. You should consider using a more robust model, this is because importance sampling is less likely to work well if the marginal posterior and LOO posterior are very different. This is more likely to happen with a non-robust model and highly influential observations.\n","  warnings.warn(\n"]},{"data":{"text/plain":["Computed from 4000 posterior samples and 204 observations log-likelihood matrix.\n","\n","         Estimate       SE\n","elpd_loo   277.21    23.02\n","p_loo       22.62        -\n","\n","There has been a warning during the calculation. Please check the results.\n","------\n","\n","Pareto k diagnostic values:\n","                         Count   Pct.\n","(-Inf, 0.5]   (good)      197   96.6%\n"," (0.5, 0.7]   (ok)          3    1.5%\n","   (0.7, 1]   (bad)         4    2.0%\n","   (1, Inf)   (very bad)    0    0.0%"]},"execution_count":13,"metadata":{},"output_type":"execute_result"}],"source":["score = az.loo(mcmc, pointwise=True)\n","score\n"]},{"cell_type":"code","execution_count":20,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["/home/vishu/repos/hbmep-paper/.venv/lib/python3.11/site-packages/arviz/stats/stats.py:1645: UserWarning: For one or more samples the posterior variance of the log predictive densities exceeds 0.4. This could be indication of WAIC starting to fail. \n","See http://arxiv.org/abs/1507.04544 for details\n","  warnings.warn(\n"]},{"data":{"text/plain":["Computed from 4000 posterior samples and 204 observations log-likelihood matrix.\n","\n","          Estimate       SE\n","elpd_waic   278.12    22.95\n","p_waic       21.71        -\n","\n","There has been a warning during the calculation. Please check the results."]},"execution_count":20,"metadata":{},"output_type":"execute_result"}],"source":["score = az.waic(mcmc, pointwise=True)\n","score\n"]},{"cell_type":"code","execution_count":15,"metadata":{},"outputs":[{"data":{"text/plain":["arviz.data.inference_data.InferenceData"]},"execution_count":15,"metadata":{},"output_type":"execute_result"}],"source":["numpyro_data = az.from_numpyro(mcmc)\n","type(numpyro_data)\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Model evaluation\n","numpyro_data = az.from_numpyro(mcmc)\n","logger.info(\"Evaluating model ...\")\n","score = az.loo(numpyro_data)\n","logger.info(f\"ELPD LOO (Log): {score.elpd_loo:.2f}\")\n","score = az.waic(numpyro_data)\n","logger.info(f\"ELPD WAIC (Log): {score.elpd_waic:.2f}\")\n","\n","# # Save posterior\n","# dest = os.path.join(model.build_dir, \"inference.pkl\")\n","# with open(dest, \"wb\") as f:\n","#     pickle.dump((model, mcmc, posterior_samples), f)\n","# logger.info(dest)\n"]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.4"}},"nbformat":4,"nbformat_minor":2}
